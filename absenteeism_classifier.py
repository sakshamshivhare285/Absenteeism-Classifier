# -*- coding: utf-8 -*-
"""Absenteeism_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AP3WV91uwqGgI3ZbyvT1ZkqfnXSW7qax
"""

import pandas as pd
import numpy as np
import matplotlib as plt

raw_data=pd.read_csv('/content/Absenteeism_data.csv')

df=raw_data.copy()

df.info()

df=df.drop(['ID'], axis=1)

df.head()

df['Reason for Absence']

pd.unique(df['Reason for Absence'])

df['Reason for Absence'].unique()

len(df['Reason for Absence'].unique())

sorted(df['Reason for Absence'].unique())

reasons=pd.get_dummies(df['Reason for Absence'], drop_first=True)

reasons.head()

age=pd.get_dummies(df['Age'])

reason_type1=reasons.loc[:,1:14].max(axis=1)

reason_type2=reasons.loc[:,15:17].max(axis=1)
reason_type3=reasons.loc[:,18:21].max(axis=1)
reason_type4=reasons.loc[:,22:].max(axis=1)

reason_type1

df=pd.concat([df,reason_type1,reason_type2,reason_type3,reason_type4], axis=1)

df.drop(['Reason for Absence'], axis=1, inplace=True)

df.head()

df.columns.values

column_names=['Date', 'Transportation Expense', 'Distance to Work', 'Age',
       'Daily Work Load Average', 'Body Mass Index', 'Education',
       'Children', 'Pets', 'Absenteeism Time in Hours', 'reason_type1', 'reason_type2', 'reason_type3', 'reason_type4']

df.columns=column_names

df.head()

column_name_reordered=['reason_type1', 'reason_type2', 'reason_type3', 'reason_type4','Date', 'Transportation Expense', 'Distance to Work', 'Age',
       'Daily Work Load Average', 'Body Mass Index', 'Education',
       'Children', 'Pets', 'Absenteeism Time in Hours']

df=df[column_name_reordered]

df_reason_mod=df.copy()

## analysis of date

type(df_reason_mod['Date'])

df_reason_mod['Date']=pd.to_datetime(df_reason_mod['Date'], format='%d/%m/%Y')

type(df_reason_mod['Date'][0])

df_reason_mod.info()

list_month=[]

for i in range(df_reason_mod.shape[0]):
  list_month.append(df_reason_mod['Date'][i].month)

df_reason_mod

df_reason_mod['month']=list_month

day_list=[]

for i in range(df_reason_mod.shape[0]):
  day_list.append(df_reason_mod['Date'][i].weekday())

df_reason_mod['day of week']= day_list

## creating the function
def day_to_weekday(date_value):
  return  date_value.weekday()

df_reason_mod['Education']=df_reason_mod['Education'].map({1:0, 2:1,3:1,4:1})

df_reason_mod['Education'].unique()

df_reason_mod['Education'].value_counts()

df_final=df_reason_mod.copy()

df_final.to_csv('absenteeism_final.csv', index=False)

data=pd.read_csv('/content/absenteeism_final.csv')

data['Absenteeism Time in Hours'].median()

targets=np.where(data['Absenteeism Time in Hours']> data['Absenteeism Time in Hours'].median(),1,0)

data['excessive absenteeism']=targets

data_target=data.drop(['Absenteeism Time in Hours'], axis=True)

data_target=data.drop(['Date'], axis=True)

unscaled_inputs=data_target.iloc[:,:-1]

## scaling the data
from sklearn.preprocessing import StandardScaler
scaler= StandardScaler()

scaler.fit(unscaled_inputs)

scaled_data=scaler.transform(unscaled_inputs)

from sklearn.model_selection import train_test_split
xtrain,xtest, ytrain,ytest=train_test_split(scaled_data, targets, test_size=0.2, shuffle=True, random_state=42)

from sklearn.linear_model import LogisticRegression
reg=LogisticRegression()

reg.fit(xtrain,ytrain)

reg.score(xtrain,ytrain)

model_output=reg.predict(xtrain)

## finding the intercepts and coefficients
reg.intercept_

feature_names=unscaled_inputs.columns.values

summary_table=pd.DataFrame(columns=['feature_names'],data=feature_names)
summary_table['coefficient']=np.transpose(reg.coef_)

summary_table.head()

summary_table.index=summary_table.index+1
summary_table.loc[0]=['intercept', reg.intercept_[0]]
summary_table=summary_table.sort_index()
summary_table

from sklearn.tree import DecisionTreeClassifier
dec=DecisionTreeClassifier()

dec.fit(xtrain,ytrain)

model=dec.predict(xtrain)

from sklearn.metrics import  classification_report, confusion_matrix

print(classification_report(ytrain,model))

## testing the model
predicted=dec.predict(xtest)

CM_dec=confusion_matrix(ytest,predicted)
print(CM_dec)

print(classification_report(ytest,predicted))

## using the randon forest
from sklearn.ensemble import RandomForestClassifier
ran=RandomForestClassifier()

ran.fit(xtrain,ytrain)

## testing the algorithm
predicted_ran=ran.predict(xtest)

CM_ran=confusion_matrix(ytest,predicted_ran)
print(CM_ran)

print(classification_report(ytest,predicted_ran))

## we would be using Random forest for creating the model
import pickle as pk

with open('ran','wb') as file:
  pk.dump(ran,file)

with open('scaler','wb') as file:
  pk.dump(scaler,file)

raw_data.columns

##creating a model
import numpy as np
import pandas as pd
import pickle
from sklearn.preprocessing import StandardScaler
from sklearn.base import BaseEstimator, TransformerMixin

##scaling the data
class Customscaler(BaseEstimator,TransformerMixin):

  def __init__(self,columns,copy=True,with_mean=True,with_std=True):
    self.scaler=StandardScaler(copy,with_mean,with_std)
    self.columns=columns
    self.mean_=None
    self.var_=None

  def fit(self,X,y=None):
    self.scaler.fit(X[self.columns],y)
    self.mean_=np.array(np.mean(X[self.columns]))
    self.var_=np.array(np.var(X[self.columns]))
    return self

  def transform(self, X,y=None,copy=None):
    init_col_order=X.columns
    X_scaled=pd.DataFrame(self.scaler.transform(X[self.columns]),columns=self.columns)
    X_not_scaled=X.loc[:,~X.columns.isin(self.columns)]
    return pd.concat([X_not_scaled,X_scaled], axis=1)[init_col_order]

## creating the absentism model
class absenteeism_model():
  def __init__(self,model_file,scaler_file):
    with open('ran','rb') as model_file, open('scaler','rb') as scaler_file:
      self.ran=pickle.load(model_file)
      self.scaler=pickle.load(scaler_file)
      self.data=None
    def load_and_clean(self,data_file):
      df=pd.rad_csv(data_file, delimiter=',')
      self.df_with_predictions=df.copy()
      df=df.drop(['ID'], axis=1)
      df['Absenteeism Time in Hours']='NaN'
      ## creating the dummies
      reason_columns=pd.get_dummies(df['Reason for Absence'], drop_first=True)
      ##spliting the columns
      reason_1=reason_columns.loc[:,1:14].max(axis=1)
      reason_2=reason_columns.loc[:,15:17].max(axis=1)
      reason_3=reason_columns.loc[:,18:21].max(axis=1)
      reason_4=reason_columns.loc[:,22:].max(axis=1)
      df.drop(['Reason for Absence'], axis=1)
      df.concat([df,reason_1,reason_2,reason_3,reason_4], axis=1)

      column_names=['Date', 'Transportation Expense',
       'Distance to Work', 'Age', 'Daily Work Load Average', 'Body Mass Index',
       'Education', 'Children', 'Pets','Absenteeism in Hours','reason_1','reason_2','reason_3','reason_4']
      df.columns=column_names

      column_names_reordered=['reason_1','reason_2','reason_3','reason_4','Date', 'Transportation Expense',
       'Distance to Work', 'Age', 'Daily Work Load Average', 'Body Mass Index',
       'Education', 'Children', 'Pets','Absenteeism in Hours']

      df=df[column_name_reordered]

      df['Date']=pd.to_datetime(df['Date'], format='%d/%m/%Y')
      list_months=[]
      for i in range(df.shape[0]):
         list_months.append(df['Date'][i].month)
      df['month']=list_months
      df['day of week']=df['Date'].apply(lambda x:x.weekday())
      df.drop(['Date'], axis=1,inplace=True)

      column_name_upd=['reason_1','reason_2','reason_3','reason_4','month','day of week', 'Transportation Expense',
       'Distance to Work', 'Age', 'Daily Work Load Average', 'Body Mass Index',
       'Education', 'Children', 'Pets','Absenteeism in Hours']

      df=df[column_name_upd]

      df['Education']=df['Education'].map({1:0,2:1,3:1,4:1})
      df=df.fillna(value=0)
      df.drop(['Absenteeism in Hours', 'day of week','Daily Work Load Average','Distance to Work'], axis=1, inplace=True)
      self.preprocessed_data=df.copy()
      self.data=self.scaler.transform(df)

       ## predicting the output
      def predicted_output_category(self):
        if (self.data is not None):
          pred_output=self.ran.predict(self.data)
          return pred_outputs

